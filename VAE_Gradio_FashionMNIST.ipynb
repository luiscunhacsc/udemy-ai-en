{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPSvyG1UwWVDq35cVj8xIrw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiscunhacsc/udemy-ai-en/blob/main/VAE_Gradio_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9mO-b71XyVp",
        "outputId": "075d6a5a-7168-4158-8cc4-4af87b21b024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q tensorflow gradio numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Conv2D, Flatten, Conv2DTranspose, Reshape, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Custom Sampling Layer\n",
        "class Sampling(Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Custom VAE Loss Layer\n",
        "class VAELoss(Layer):\n",
        "    def call(self, inputs):\n",
        "        x, x_decoded, z_mean, z_log_var = inputs\n",
        "        reconstruction_loss = BinaryCrossentropy()(tf.keras.backend.flatten(x), tf.keras.backend.flatten(x_decoded))\n",
        "        reconstruction_loss *= 28 * 28\n",
        "        kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "        kl_loss = tf.reduce_sum(kl_loss, axis=-1)\n",
        "        kl_loss *= -0.5\n",
        "        total_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
        "        self.add_loss(total_loss)\n",
        "        return x_decoded\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "latent_dim = 5\n",
        "\n",
        "# Encoder\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "x = Conv2D(32, 3, activation='relu', strides=2, padding='same')(inputs)\n",
        "x = Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(x)\n",
        "z_log_var = Dense(latent_dim)(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "\n",
        "# Decoder\n",
        "latent_inputs = Input(shape=(latent_dim,))\n",
        "x = Dense(7 * 7 * 64, activation='relu')(latent_inputs)\n",
        "x = Reshape((7, 7, 64))(x)\n",
        "x = Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "x = Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
        "outputs = Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "# VAE\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae_outputs = VAELoss()([inputs, outputs, encoder(inputs)[0], encoder(inputs)[1]])\n",
        "vae = Model(inputs, vae_outputs, name='vae')\n",
        "\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()\n",
        "\n",
        "# Train the VAE\n",
        "vae.fit(x_train, epochs=30, batch_size=128, validation_data=(x_test, None))\n",
        "\n",
        "# Function to visualize the latent space (only possible for 2D latent spaces, not applicable here)\n",
        "def plot_latent_space():\n",
        "    pass\n",
        "\n",
        "# Function to generate new samples\n",
        "def generate_sample(z1, z2, z3, z4, z5):\n",
        "    z_sample = np.array([[z1, z2, z3, z4, z5]])\n",
        "    x_decoded = decoder.predict(z_sample)\n",
        "    digit = x_decoded[0].reshape(28, 28)\n",
        "    return digit\n",
        "\n",
        "# Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_sample,\n",
        "    inputs=[\n",
        "        gr.Slider(-4, 4, value=0, label=\"Latent Variable 1\"),\n",
        "        gr.Slider(-4, 4, value=0, label=\"Latent Variable 2\"),\n",
        "        gr.Slider(-4, 4, value=0, label=\"Latent Variable 3\"),\n",
        "        gr.Slider(-4, 4, value=0, label=\"Latent Variable 4\"),\n",
        "        gr.Slider(-4, 4, value=0, label=\"Latent Variable 5\")\n",
        "    ],\n",
        "    outputs=gr.Image(image_mode='L'),\n",
        "    live=True,\n",
        "    description=\"Move the sliders to change the latent variables and generate different images.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SQqDO8ihX6p8",
        "outputId": "1c245ee6-8709-4fd6-d051-48783604b9c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n",
            "Model: \"vae\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " encoder (Functional)        [(None, 5),                  69178     ['input_1[0][0]',             \n",
            "                              (None, 5),                             'input_1[0][0]',             \n",
            "                              (None, 5)]                             'input_1[0][0]']             \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, 28, 28, 1)            74497     ['encoder[0][2]']             \n",
            "                                                                                                  \n",
            " vae_loss (VAELoss)          (None, 28, 28, 1)            0         ['input_1[0][0]',             \n",
            "                                                                     'decoder[0][0]',             \n",
            "                                                                     'encoder[1][0]',             \n",
            "                                                                     'encoder[2][1]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 143675 (561.23 KB)\n",
            "Trainable params: 143675 (561.23 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "469/469 [==============================] - 20s 14ms/step - loss: 313.3191 - val_loss: 264.4561\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 257.8344 - val_loss: 256.3940\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 253.2701 - val_loss: 253.5000\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 251.0721 - val_loss: 251.8904\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 249.7888 - val_loss: 250.8206\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 248.9256 - val_loss: 250.2638\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 248.1534 - val_loss: 249.6630\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 247.7254 - val_loss: 249.4300\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 247.3107 - val_loss: 248.9539\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 246.9664 - val_loss: 248.9053\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 246.6949 - val_loss: 249.4617\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 246.4828 - val_loss: 248.4691\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 246.1992 - val_loss: 248.8521\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 246.0266 - val_loss: 247.7668\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 245.8105 - val_loss: 248.1849\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 245.6541 - val_loss: 247.5716\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 245.5100 - val_loss: 248.0513\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 245.3491 - val_loss: 247.4308\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 245.2086 - val_loss: 247.1838\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 245.1376 - val_loss: 247.1149\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 244.9918 - val_loss: 246.7935\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 244.9044 - val_loss: 246.9832\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 244.7463 - val_loss: 246.9848\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 244.6387 - val_loss: 246.8095\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 244.5759 - val_loss: 246.7896\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 244.5062 - val_loss: 246.5324\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 244.3803 - val_loss: 246.4910\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 244.3382 - val_loss: 246.5980\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 244.2150 - val_loss: 246.4694\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 244.1456 - val_loss: 246.6163\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://954966704e412be18c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://954966704e412be18c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}