{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiscunhacsc/udemy-ai-en/blob/main/part1b_vision/part1b_example02_vgg16_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pNBACYlW0-bY",
      "metadata": {
        "id": "pNBACYlW0-bY"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this example, we will learn how to use pre-trained models for image classification. We will use the \"CIFAR-10\" dataset, which consists of 60,000 32x32 color images divided into 10 different classes.\n",
        "\n",
        "We will start by using a pre-trained model directly to classify images. Then, we will perform freezing and fine-tuning of the model to better adapt it to our dataset. Finally, we will explore some additional techniques such as data augmentation and regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_w8Ns9q30-bf",
      "metadata": {
        "id": "_w8Ns9q30-bf"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yTixfsKg0-bh",
      "metadata": {
        "id": "yTixfsKg0-bh"
      },
      "source": [
        "# Load the CIFAR-10 dataset\n",
        "\n",
        "The CIFAR-10 dataset contains 60,000 32x32 color images divided into 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g8nk41qm0-bi",
      "metadata": {
        "id": "g8nk41qm0-bi"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12lOW9vv0-bj",
      "metadata": {
        "id": "12lOW9vv0-bj"
      },
      "source": [
        "# Using a pre-trained model\n",
        "\n",
        "Let's start by using the VGG16 model, which is pre-trained on the ImageNet dataset, to classify the CIFAR-10 images. We will use the model directly without any modifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ekXMrALB0-bl",
      "metadata": {
        "id": "ekXMrALB0-bl"
      },
      "outputs": [],
      "source": [
        "# Use the pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "predictions = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Build the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Evaluate the performance of the pre-trained model on the test set\n",
        "evaluation = model.evaluate(test_images, test_labels)\n",
        "print(f\"Accuracy of the pre-trained model on the test set: {evaluation[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ztB1oTir0-bm",
      "metadata": {
        "id": "ztB1oTir0-bm"
      },
      "source": [
        "# Fine-tuning the pre-trained model\n",
        "\n",
        "Now, let's perform the fine-tuning of the pre-trained model. Initially, we will freeze all the layers of the base model (VGG16) and train only the top layers that we added. This is called \"feature extraction\". Then, we will unfreeze some of the layers of the base model and perform fine-tuning together with the added layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HhQwXs5a0-bm",
      "metadata": {
        "id": "HhQwXs5a0-bm"
      },
      "outputs": [],
      "source": [
        "# Feature extraction - freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_feature_extraction = model.fit(train_images, train_labels, batch_size=128, epochs=5, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bkBkezy70-bn",
      "metadata": {
        "id": "bkBkezy70-bn"
      },
      "source": [
        "# Unfreeze some layers and perform fine-tuning\n",
        "\n",
        "Now let's unfreeze some of the layers of the base model and perform fine-tuning together with the added layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfAQmMm0-bo",
      "metadata": {
        "id": "9dfAQmMm0-bo"
      },
      "outputs": [],
      "source": [
        "# Unfreeze layers and perform fine-tuning\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_fine_tuning = model.fit(train_images, train_labels, batch_size=128, epochs=5, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VaWYX2I30-bp",
      "metadata": {
        "id": "VaWYX2I30-bp"
      },
      "source": [
        "\n",
        "# Data Augmentation\n",
        "\n",
        "Data Augmentation increases the size of the training set by creating modified versions of the images, such as rotations, shifts, and zooms. This can help improve the performance and generalization of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FPEgNWsS0-bp",
      "metadata": {
        "id": "FPEgNWsS0-bp"
      },
      "outputs": [],
      "source": [
        "# Use Data Augmentation\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2)\n",
        "])\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Build the final model with Data Augmentation\n",
        "model_with_augmentation = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_with_augmentation.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history_with_augmentation = model_with_augmentation.fit(train_images, train_labels, batch_size=128, epochs=5, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qwVV4MCa0-bq",
      "metadata": {
        "id": "qwVV4MCa0-bq"
      },
      "source": [
        "# Visualizing the results\n",
        "\n",
        "Now let's visualize the performance of the models at different stages: using the pre-trained model directly, after feature extraction, after fine-tuning, and after data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wgq5Vpi_0-bq",
      "metadata": {
        "id": "wgq5Vpi_0-bq"
      },
      "outputs": [],
      "source": [
        "# Visualization of results\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_feature_extraction.history['val_accuracy'], label='Feature Extraction')\n",
        "plt.plot(history_fine_tuning.history['val_accuracy'], label='Fine-tuning')\n",
        "plt.plot(history_with_augmentation.history['val_accuracy'], label='Data Augmentation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Model Performance')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_feature_extraction.history['val_loss'], label='Feature Extraction')\n",
        "plt.plot(history_fine_tuning.history['val_loss'], label='Fine-tuning')\n",
        "plt.plot(history_with_augmentation.history['val_loss'], label='Data Augmentation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title('Model Performance')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-gEp2Eci0-bq",
      "metadata": {
        "id": "-gEp2Eci0-bq"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "In this example, we explored different techniques to leverage pre-trained models for image classification. We used the CIFAR-10 dataset and the pre-trained VGG16 model.\n",
        "\n",
        "We started by using the model directly, then performed feature extraction, followed by fine-tuning, and finally used data augmentation.\n",
        "\n",
        "It is important to note that choosing the best techniques and hyperparameters may depend on the dataset and the specific problem. Experimenting and evaluating different approaches is an important part of the deep learning model development process."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}