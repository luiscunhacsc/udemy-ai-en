{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1b6ca10a",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiscunhacsc/udemy-ia-pt/blob/main/parte1b_visao/parte1b_exemplo02_vgg16_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pNBACYlW0-bY",
      "metadata": {
        "id": "pNBACYlW0-bY"
      },
      "source": [
        "# Introdução\n",
        "\n",
        "Neste exemplo, vamos aprender como usar modelos pré-treinados para classificação de imagens. Vamos utilizar o conjunto de dados \"CIFAR-10\", que consiste em 60.000 imagens a cores de 32x32 divididas em 10 classes diferentes.\n",
        "\n",
        "Começaremos utilizando um modelo pré-treinado diretamente para classificar imagens. Em seguida, vamos realizar o \"freezing\" e o \"fine-tuning\" do modelo para adaptá-lo melhor ao nosso conjunto de dados. Por fim, vamos explorar algumas técnicas adicionais, como o \"data augmentation\" e a regularização."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_w8Ns9q30-bf",
      "metadata": {
        "id": "_w8Ns9q30-bf"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yTixfsKg0-bh",
      "metadata": {
        "id": "yTixfsKg0-bh"
      },
      "source": [
        "# Carregar o conjunto de dados CIFAR-10\n",
        "\n",
        "O conjunto de dados CIFAR-10 contém 60.000 imagens a cores de 32x32, divididas em 10 classes, com 6.000 imagens por classe. Existem 50.000 imagens de treino e 10.000 imagens de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g8nk41qm0-bi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8nk41qm0-bi",
        "outputId": "ca2d2f29-24c7-4e2d-c204-a23dcbea73ac"
      },
      "outputs": [],
      "source": [
        "# Carregar o conjunto de dados\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalizar os dados\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Converter os rótulos para one-hot encoding\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12lOW9vv0-bj",
      "metadata": {
        "id": "12lOW9vv0-bj"
      },
      "source": [
        "# Uso de um modelo pré-treinado\n",
        "\n",
        "Vamos começar usando o modelo VGG16, que é pré-treinado no conjunto de dados ImageNet, para classificar as imagens CIFAR-10. Usaremos o modelo diretamente sem qualquer modificação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ekXMrALB0-bl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekXMrALB0-bl",
        "outputId": "c8a895c4-38f9-4915-fd6a-87b0f8ddb73d"
      },
      "outputs": [],
      "source": [
        "# Célula 6: Usar o modelo VGG16 pré-treinado\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Adicionar camadas de classificação personalizadas\n",
        "x = base_model.output\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "predictions = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Construir o modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Avaliar o desempenho do modelo pré-treinado no conjunto de teste\n",
        "evaluation = model.evaluate(test_images, test_labels)\n",
        "print(f\"Acurácia do modelo pré-treinado no conjunto de teste: {evaluation[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ztB1oTir0-bm",
      "metadata": {
        "id": "ztB1oTir0-bm"
      },
      "source": [
        "# Fine-tuning do modelo pré-treinado\n",
        "\n",
        "Agora, vamos realizar o \"fine-tuning\" do modelo pré-treinado. Inicialmente, vamos congelar todas as camadas do\n",
        "\n",
        "modelo base (VGG16) e treinar apenas as camadas superiores que adicionamos. Isto é chamado de \"feature extraction\". Depois, vamos descongelar algumas das camadas do modelo base e realizar um ajuste fino em conjunto com as camadas adicionadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HhQwXs5a0-bm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhQwXs5a0-bm",
        "outputId": "6cf2e599-ef35-4851-f1ba-b326bb39bdd4"
      },
      "outputs": [],
      "source": [
        "# Feature extraction - congelar as camadas do modelo base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history_feature_extraction = model.fit(train_images, train_labels, batch_size=128, epochs=5, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bkBkezy70-bn",
      "metadata": {
        "id": "bkBkezy70-bn"
      },
      "source": [
        "# Descongelar algumas camadas e realizar ajuste fino\n",
        "\n",
        "Agora vamos descongelar algumas das camadas do modelo base e realizar o ajuste fino em conjunto com as camadas adicionadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfAQmMm0-bo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dfAQmMm0-bo",
        "outputId": "ca08ba7d-b7ae-484b-a481-760dba30dbe7"
      },
      "outputs": [],
      "source": [
        "# Descongelar camadas e realizar ajuste fino\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history_fine_tuning = model.fit(train_images, train_labels, batch_size=128, epochs=5, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VaWYX2I30-bp",
      "metadata": {
        "id": "VaWYX2I30-bp"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "O \"Data Augmentation\" aumenta o tamanho do conjunto de treino através da criação de versões modificadas das imagens, como rotações, deslocamentos e zooms. Isto pode ajudar a melhorar o desempenho e a generalização do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FPEgNWsS0-bp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPEgNWsS0-bp",
        "outputId": "151950f4-4e39-4318-b100-f9b1b62696e0"
      },
      "outputs": [],
      "source": [
        "# Utilizar Data Augmentation\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2)\n",
        "])\n",
        "\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Construir o modelo final com Data Augmentation\n",
        "model_with_augmentation = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compilar o modelo\n",
        "model_with_augmentation.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "history_with_augmentation = model_with_augmentation.fit(train_images, train_labels, batch_size=128, epochs=5, validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qwVV4MCa0-bq",
      "metadata": {
        "id": "qwVV4MCa0-bq"
      },
      "source": [
        "# Visualizar os resultados\n",
        "\n",
        "Vamos agora visualizar o desempenho dos modelos em diferentes fases: uso direto do modelo pré-treinado, após \"feature extraction\", após ajuste fino e após \"data augmentation\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wgq5Vpi_0-bq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "wgq5Vpi_0-bq",
        "outputId": "6a21d7ae-76f0-4568-9321-0af838906849"
      },
      "outputs": [],
      "source": [
        "# Visualização dos resultados\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_feature_extraction.history['val_accuracy'], label='Feature Extraction')\n",
        "plt.plot(history_fine_tuning.history['val_accuracy'], label='Fine-tuning')\n",
        "\n",
        "\n",
        "plt.plot(history_with_augmentation.history['val_accuracy'], label='Data Augmentation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.title('Desempenho do Modelo')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_feature_extraction.history['val_loss'], label='Feature Extraction')\n",
        "plt.plot(history_fine_tuning.history['val_loss'], label='Fine-tuning')\n",
        "plt.plot(history_with_augmentation.history['val_loss'], label='Data Augmentation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title('Desempenho do Modelo')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-gEp2Eci0-bq",
      "metadata": {
        "id": "-gEp2Eci0-bq"
      },
      "source": [
        "# Conclusão\n",
        "\n",
        "Neste exemplo, explorámos diferentes técnicas para aproveitar os modelos pré-treinados para classificação de imagens. Utilizámos o conjunto de dados CIFAR-10 e o modelo VGG16 pré-treinado.\n",
        "\n",
        "Começámos utilizando o modelo diretamente, depois fizemos \"feature extraction\", seguido de ajuste fino e, finalmente, utilizámos \"data augmentation\".\n",
        "\n",
        "É importante notar que escolher as melhores técnicas e hiperparâmetros pode depender do conjunto de dados e do problema específico. Experimentar e avaliar diferentes abordagens é uma parte importante do processo de desenvolvimento de modelos de deep learning."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
