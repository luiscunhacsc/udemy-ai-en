{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luiscunhacsc/udemy-ai-en/blob/main/part4_generative_ai/VAE_Gradio/VAE_with_Gradio_and_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqcHEe7pUpJF"
      },
      "outputs": [],
      "source": [
        "%pip install -q tensorflow gradio numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t_436hjoUwoP",
        "outputId": "533e6c8a-c5e5-4346-f6d8-a98cfe6d07ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vae\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " encoder (Functional)        [(None, 2),                  69076     ['input_5[0][0]',             \n",
            "                              (None, 2),                             'input_5[0][0]',             \n",
            "                              (None, 2)]                             'input_5[0][0]']             \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, 28, 28, 1)            65089     ['encoder[0][2]']             \n",
            "                                                                                                  \n",
            " vae_loss_2 (VAELoss)        (None, 28, 28, 1)            0         ['input_5[0][0]',             \n",
            "                                                                     'decoder[0][0]',             \n",
            "                                                                     'encoder[1][0]',             \n",
            "                                                                     'encoder[2][1]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134165 (524.08 KB)\n",
            "Trainable params: 134165 (524.08 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "469/469 [==============================] - 18s 25ms/step - loss: 217.1350 - val_loss: 196.3697\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 185.3120 - val_loss: 175.0495\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 170.0568 - val_loss: 166.4173\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 164.6506 - val_loss: 162.9339\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 161.8591 - val_loss: 160.9420\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 160.0606 - val_loss: 159.6410\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 158.7215 - val_loss: 158.4053\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 157.7851 - val_loss: 157.7226\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 156.7782 - val_loss: 156.5701\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 156.0148 - val_loss: 156.2146\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 155.4070 - val_loss: 155.4905\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 154.8650 - val_loss: 155.1041\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 154.4267 - val_loss: 155.5088\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 154.0028 - val_loss: 155.0258\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 153.5107 - val_loss: 154.0558\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 153.2423 - val_loss: 154.3967\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 152.8660 - val_loss: 153.7579\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 152.7086 - val_loss: 153.1993\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 152.3689 - val_loss: 153.2915\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 152.2244 - val_loss: 153.3597\n",
            "Epoch 21/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 151.9137 - val_loss: 152.8241\n",
            "Epoch 22/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 151.7366 - val_loss: 152.9222\n",
            "Epoch 23/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 151.5306 - val_loss: 152.7736\n",
            "Epoch 24/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 151.4099 - val_loss: 153.0157\n",
            "Epoch 25/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 151.2045 - val_loss: 152.7799\n",
            "Epoch 26/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 151.0005 - val_loss: 152.1671\n",
            "Epoch 27/30\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 150.8727 - val_loss: 152.3735\n",
            "Epoch 28/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 150.6213 - val_loss: 152.5307\n",
            "Epoch 29/30\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 150.6052 - val_loss: 152.1803\n",
            "Epoch 30/30\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 150.3757 - val_loss: 152.2232\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://0586af155c4c7a6573.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0586af155c4c7a6573.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda, Conv2D, Flatten, Conv2DTranspose, Reshape, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Custom Sampling Layer\n",
        "class Sampling(Layer):\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Custom VAE Loss Layer\n",
        "class VAELoss(Layer):\n",
        "    def call(self, inputs):\n",
        "        x, x_decoded, z_mean, z_log_var = inputs\n",
        "        reconstruction_loss = BinaryCrossentropy()(tf.keras.backend.flatten(x), tf.keras.backend.flatten(x_decoded))\n",
        "        reconstruction_loss *= 28 * 28\n",
        "        kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "        kl_loss = tf.reduce_sum(kl_loss, axis=-1)\n",
        "        kl_loss *= -0.5\n",
        "        total_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
        "        self.add_loss(total_loss)\n",
        "        return x_decoded\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "latent_dim = 2\n",
        "\n",
        "# Encoder\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "x = Conv2D(32, 3, activation='relu', strides=2, padding='same')(inputs)\n",
        "x = Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(x)\n",
        "z_log_var = Dense(latent_dim)(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "\n",
        "# Decoder\n",
        "latent_inputs = Input(shape=(latent_dim,))\n",
        "x = Dense(7 * 7 * 64, activation='relu')(latent_inputs)\n",
        "x = Reshape((7, 7, 64))(x)\n",
        "x = Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
        "x = Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
        "outputs = Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "# VAE\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae_outputs = VAELoss()([inputs, outputs, encoder(inputs)[0], encoder(inputs)[1]])\n",
        "vae = Model(inputs, vae_outputs, name='vae')\n",
        "\n",
        "vae.compile(optimizer='adam')\n",
        "vae.summary()\n",
        "\n",
        "# Train the VAE\n",
        "vae.fit(x_train, epochs=30, batch_size=128, validation_data=(x_test, None))\n",
        "\n",
        "# Function to visualize the latent space (only possible for 2D latent spaces, not applicable here)\n",
        "def plot_latent_space():\n",
        "    pass\n",
        "\n",
        "# Function to generate new samples\n",
        "def generate_sample(z1, z2):\n",
        "    z_sample = np.array([[z1, z2]])\n",
        "    x_decoded = decoder.predict(z_sample)\n",
        "    digit = x_decoded[0].reshape(28, 28)\n",
        "    return digit\n",
        "\n",
        "# Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_sample,\n",
        "    inputs=[\n",
        "        gr.Slider(-4, 4, value=0, label=\"Latent Variable 1\"),\n",
        "        gr.Slider(-4, 4, value=0, label=\"Latent Variable 2\")\n",
        "    ],\n",
        "    outputs=gr.Image(image_mode='L'),\n",
        "    live=True,\n",
        "    description=\"Move the sliders to change the latent variables and generate different digit images.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}