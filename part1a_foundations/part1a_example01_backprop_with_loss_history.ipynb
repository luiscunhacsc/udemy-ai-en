{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d87b9c27",
   "metadata": {},
   "source": [
    "# Neural Network Backpropagation Example\n",
    "\n",
    "This notebook demonstrates a simple implementation of a neural network with backpropagation. The example includes defining the sigmoid activation function, initializing weights, and training the network over a specified number of epochs. Let's go through the implementation step by step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0c787",
   "metadata": {},
   "source": [
    "## Installing Necessary Libraries\n",
    "\n",
    "Before we begin, we need to ensure that the necessary libraries are installed. This includes `numpy` for numerical computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecee969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install numpy\n",
    "%pip install -q numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f89bb",
   "metadata": {},
   "source": [
    "## Defining the Sigmoid Function\n",
    "\n",
    "The sigmoid function is used as the activation function in our neural network. We also define its derivative, which is necessary for the backpropagation step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37bb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f842f41",
   "metadata": {},
   "source": [
    "## Initializing Inputs, Outputs, and Weights\n",
    "\n",
    "We initialize the input values, expected output values, and the initial weights for both the hidden and output layers. Additionally, we set the learning rate and the number of training epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26c7b3",
   "metadata": {},
   "source": [
    "<img src=\"images_for_part1a_code\\sample_network_part1a.png\" alt=\"Image of the network used in the code\" width=\"700\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15017ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input values\n",
    "inputs = np.array([0.5, 0.9, -0.3])\n",
    "\n",
    "# Expected output values (ground truth)\n",
    "expected_output = np.array([0.9, 0.3])\n",
    "\n",
    "# Initial weights for the hidden layer\n",
    "weights_hidden = np.array([[1.0, -2.0, 2.0],   # weights from input to hidden layer neurons\n",
    "                           [2.0, 1.0, -4.0],   # weights from input to hidden layer neurons\n",
    "                           [1.0, -1.0, 0.0]])  # weights from input to hidden layer neurons\n",
    "\n",
    "# Initial weights for the output layer\n",
    "weights_output = np.array([[-3.0, 1.0, -3.0],  # weights from hidden to output layer neurons\n",
    "                           [0.0, 1.0, 2.0]])   # weights from hidden to output layer neurons\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff37c5",
   "metadata": {},
   "source": [
    "## Training the Neural Network\n",
    "\n",
    "We train the neural network using forward propagation to calculate the output and backpropagation to update the weights. The training process runs for the specified number of epochs, and we print the loss every 10% of the epochs to monitor the training progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c875f5ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (2,3) not aligned: 3 (dim 0) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m hidden_layer_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(inputs, weights_hidden)\n\u001b[0;32m      8\u001b[0m hidden_layer_activation \u001b[38;5;241m=\u001b[39m sigmoid(hidden_layer_input)\n\u001b[1;32m---> 10\u001b[0m output_layer_input \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_layer_activation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m final_output \u001b[38;5;241m=\u001b[39m sigmoid(output_layer_input)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Calculate the loss (Mean Squared Error)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,) and (2,3) not aligned: 3 (dim 0) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize loss history\n",
    "loss_history = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    hidden_layer_input = np.dot(inputs, weights_hidden)\n",
    "    hidden_layer_activation = sigmoid(hidden_layer_input)\n",
    "    \n",
    "    output_layer_input = np.dot(hidden_layer_activation, weights_output)\n",
    "    final_output = sigmoid(output_layer_input)\n",
    "    \n",
    "    # Calculate the loss (Mean Squared Error)\n",
    "    loss = np.mean((expected_output - final_output) ** 2)\n",
    "    loss_history.append(loss)  # Record the loss\n",
    "    \n",
    "    # Backward pass\n",
    "    error_output_layer = expected_output - final_output\n",
    "    d_output_layer = error_output_layer * sigmoid_derivative(final_output)\n",
    "    \n",
    "    error_hidden_layer = d_output_layer.dot(weights_output.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_activation)\n",
    "    \n",
    "    # Update weights\n",
    "    weights_output += hidden_layer_activation.T.dot(d_output_layer) * learning_rate\n",
    "    weights_hidden += inputs.T.dot(d_hidden_layer) * learning_rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daff1dd",
   "metadata": {},
   "source": [
    "## Final Results\n",
    "\n",
    "After training, we print the final weights of the hidden and output layers, as well as the expected and obtained final output values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results after training with 1000 epochs: \n",
      "\n",
      "Final weights of the hidden layer: \n",
      "[[ 0.78535854 -2.38635463  2.12878488]\n",
      " [ 2.05894493  1.10610087 -4.03536696]\n",
      " [ 0.30605228 -2.2491059   0.41636863]]\n",
      "\n",
      "Final weights of the output layer: \n",
      "[[-2.82735452  2.6021329  -2.62164075]\n",
      " [-0.21514193 -1.04321128  1.55538615]]\n",
      "\n",
      "\n",
      "Expected final values (output): [0.9 0.3]\n",
      "Obtained final values (output): [0.87579945 0.3024596 ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print final results\n",
    "print(f\"\\n\\nResults after training with {epochs} epochs: \")\n",
    "print(f\"\\nFinal weights of the hidden layer: \\n{weights_hidden}\")\n",
    "print(f\"\\nFinal weights of the output layer: \\n{weights_output}\")\n",
    "print(f\"\\n\\nExpected final values (output): {expected_output}\")\n",
    "print(f\"Obtained final values (output): {final_output}\")\n",
    "print(f\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efef11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the loss after training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'loss_history' is a list that stores the loss at each epoch\n",
    "plt.plot(loss_history)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
